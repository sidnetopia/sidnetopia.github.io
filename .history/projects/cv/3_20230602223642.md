## Mutual Learning Approach to Distracted Driver Behavior Detection

**Project description:** Distracted driver behavior recognition aims to prevent accidents by alerting drivers of distracted driving. This study investigates the potential mutual learning between specific-object detectors to improve accuracy by combining their results to achieve a comprehensive understanding of the driver's cabin space. The recognized scene is then used to reevaluate the predicted objects and their locations within the cabin, such as the driver's face, hands, steering wheel, cigarette, handphone, sandwich, coffee mug, and more.

### 1. Learning architecture of the system

The upper part of the model
The behavior is predicted using the entire image, while the lower part of the model employs specific object detectors. The face detector results are represented by yellow bounding boxes, the hands detector results by green bounding boxes, and the steering detector result by a blue bounding box. By combining the outputs of individual object detectors, a scene prediction is generated. The image classifier and ensemble of object detectors learn collaboratively, each with its own supervised learning loss. Additionally, a mimicry loss based on Kullback-Leibler Divergence is employed to align the probability estimates of the different components (Y. Zhang et al., 2018).

<img src="images/cv/project_2/interface.png?raw=true"/>

### 2. Dataset used

This study utilized a subset of the 3MDAD dataset (Jegham et al., 2020) for training and testing the model. This dataset covers a variety of real-world detection challenges such as occlusions, blurry video frames, and different lighting and weather conditions. The side-view set of the dataset was chosen as it contains bounding boxes for the face and hands. We then extend this dataset by adding phone, cigarette, drink, operational device, and steering wheel bounding box annotations. For training, images of 30 subjects were used, while the images of 10 subjects were used for validation and 10 for testing.

<img src="images/cv/project_2/detecting_passenger_1.gif?raw=true"/>
<img src="images/cv/project_2/detecting_passenger_2.gif?raw=true"/>

### 3. Recognizing the Passenger

The application quantifies the "color distribution" linked to an individual as they board the vehicle.

The application utilizes the "color distribution" to identify an individual as they disembark from the vehicle.

<img src="images/cv/project_2/recognizing_the_passenger_1.png?raw=true"/>

Subsequently, the application computes the "similarity" between the image of the departing passenger and each passenger present inside the vehicle.

The application then chooses the image that exhibits the highest level of similarity.

<img src="images/cv/project_2/recognizing_the_passenger_2.png?raw=true"/>
