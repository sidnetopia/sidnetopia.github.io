## This can be your internal website page / project page

**Project description:** Drawings have been interpreted in various ways throughout different periods, making it challenging to provide a definitive definition. These drawings, created using different techniques, have been utilized to assess a child's intelligence. Numerous studies have examined children's drawings, including Goodenough's (1926) research, which involved extracting information from the depicted subject to predict mental age and intelligence quotient (IQ). Additionally, computer-aided tests have become increasingly significant in recent research, as they offer a more suitable approach for detecting categorical drawing characteristics using mathematical models.

Therefore, the aim of this project is to computerize Goodenough's (1926) research. By utilizing a Convolutional Neural Network (CNN) as the sketch processor, the project classifies drawings into specific mental age categories and determines corresponding intelligence quotient (IQ) based on its learned or trained knowledge. Three methods were employed for image processing: the Basic CNN Structure, CNN Architecture with Sparse Matrix, and CNN Architecture with Sparse Matrix (Halved). These methods were tested using two types of fully connected layers: 256 and 512 Fully Connected Layers.

Among the trained methods, the Basic Model with a 512 fully connected layer demonstrated the highest performance, achieving a validation accuracy of 92% and a training accuracy peak of 82%. The Confusion Matrix displayed an accuracy of 89.97% and an error rate of 0.10, while the Categorical Cross Entropy yielded an accuracy of 89.97% and a score of 32.20%. Consequently, this model was selected for further analysis. This project provides evidence of the computer's potential to predict a child's Intelligence Quotient based on their drawings.

### 1. Overview of the Project

<img src="images/dummy_thumbnail.png?raw=true"/>

### 2. Data Gathering and Augmentation

The Draw-a-Person test (Goodenough, 1926) was conducted with elementary pupils of NDMU-IBED, using paper and pencil, to evaluate their ability to depict a person. Prior to the test, permission was obtained from the school authorities.

To enhance result accuracy and ensure reliable labeling, additional data from Goodenough's book (1926) was incorporated into the study. This data had been validated by the author, helping to increase the sample size and filter out classes with insufficient data.

Following the collection of drawings, we proceeded to scan and process them by eliminating noise, trimming whitespace, and resizing them to 150 by 150 pixels. Noise removal involved creating a hull around the image, excluding any points below the threshold stroke. In total, the drawings that are collected were 726 in total.

Subsequently, the dataset was divided into a 60/20/20 split, and data augmentation was applied by rotating the drawings between -45 and 45 degrees. This approach ensured that the figures accurately represented people and provided a diverse dataset for the model. To mitigate potential misrepresentations caused by overlapping in the drawings, a whitespace border was introduced.

Furthermore, drawings that were misinterpreted or obstructed in a specific manner were clustered. This allowed the model to learn from these examples and prevent misclassification. The underlying objective of this methodology was to enable the model to recognize and distinguish flawed instances.

<img src="images/dataset.png?raw=true"/>

### 3. Model Selection and Validation

During the model selection process, three models were chosen. Firstly, a basic CNN model was employed, utilizing shallow convolutional neural networks. Additionally, we incorporated the sparse convolutional model proposed by Sunghaba (2017), as it was considered one of the novel sketch classifiers at the time of this project's creation. Furthermore, we made necessary modifications to adapt the model to our specific requirements.
