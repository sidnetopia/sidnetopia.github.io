## Mutual Learning Approach to Distracted Driver Behavior Detection

**Project description:** Distracted driver behavior recognition aims to prevent accidents by alerting drivers of distracted driving. This study investigates the potential mutual learning between specific-object detectors to improve accuracy by combining their results to achieve a comprehensive understanding of the driver's cabin space. The recognized scene is then used to reevaluate the predicted objects and their locations within the cabin, such as the driver's face, hands, steering wheel, cigarette, handphone, sandwich, coffee mug, and more.

### 1. Learning architecture of the system

The upper part of the model
predicts the behavior using the whole image. The lower part of the model utilizes specific object detectors. Yellow
bounding boxes are the face detector results. Green bounding boxes are the hands detector results. Blue bounding box
is the steering detector result. The result of individual object detectors are combined to provide a scene prediction. The
image classifier and ensemble of object detectors learn mutually, each having supervised learning loss, and a Kullback
Leibler Divergence based mimicry loss to match the probability estimates of one another.(Y. Zhang et al., 2018).
<img src="images/cv/project_2/interface.png?raw=true"/>

### 2. Detecting the passenger

The app currently employs conventional computer vision techniques to accomplish the following tasks:

Differentiate the foreground object (i.e., passenger) from the background.
Identify pixels that belong to the same foreground object.
These operations involve standard computer vision procedures such as erosion, dilation, background subtraction, and contour detection.

<img src="images/cv/project_2/detecting_passenger_1.gif?raw=true"/>
<img src="images/cv/project_2/detecting_passenger_2.gif?raw=true"/>

### 3. Recognizing the Passenger

The application quantifies the "color distribution" linked to an individual as they board the vehicle.

The application utilizes the "color distribution" to identify an individual as they disembark from the vehicle.

<img src="images/cv/project_2/recognizing_the_passenger_1.png?raw=true"/>

Subsequently, the application computes the "similarity" between the image of the departing passenger and each passenger present inside the vehicle.

The application then chooses the image that exhibits the highest level of similarity.

<img src="images/cv/project_2/recognizing_the_passenger_2.png?raw=true"/>
